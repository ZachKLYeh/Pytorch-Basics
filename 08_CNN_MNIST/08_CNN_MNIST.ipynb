{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set device\n",
    "#if cuda is available then use cuda, else use cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare parameters\n",
    "\n",
    "input_size = 784 #image size = 28x28 --flatten 784\n",
    "n_classes = 10\n",
    "n_epoch = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip dataset to test_images, test_labels, train_images, train_labels as numpy\n",
    "\n",
    "file = r'/home/zacharyyeh/Datasets/MNIST/t10k-images.idx3-ubyte'\n",
    "test_images = idx2numpy.convert_from_file(file)\n",
    "file = r'/home/zacharyyeh/Datasets/MNIST/t10k-labels.idx1-ubyte'\n",
    "test_labels = idx2numpy.convert_from_file(file)\n",
    "file = r'/home/zacharyyeh/Datasets/MNIST/train-images.idx3-ubyte'\n",
    "train_images = idx2numpy.convert_from_file(file)\n",
    "file = r'/home/zacharyyeh/Datasets/MNIST/train-labels.idx1-ubyte'\n",
    "train_labels = idx2numpy.convert_from_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build children class TrainSet, TestSet from parent class Dataset \n",
    "\n",
    "class TrainSet(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        self.train_images = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.n_samples = train_images.shape[0]\n",
    "        #Important!!!! add a channel to images [28, 28] to [1, 28, 28] so that i can be seen as a image\n",
    "        self.train_images = np.resize(self.train_images, (self.n_samples, 1, 28,28))\n",
    "        #Transpouse to fit ToTensor input form!!!! [samples c h w] to [samples h w c]\n",
    "        self.train_images = np.transpose(self.train_images, (0, 2, 3, 1))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.train_images[index], self.train_labels[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class TestSet(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        self.test_images = test_images\n",
    "        self.test_labels = test_labels\n",
    "        self.n_samples = test_images.shape[0]\n",
    "        self.test_images = np.resize(self.test_images, (self.n_samples, 1, 28,28))\n",
    "        self.test_images = np.transpose(self.test_images, (0, 2, 3, 1))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.test_images[index], self.test_labels[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "#Make dataset with transform included\n",
    "\n",
    "composed = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = (0.5,), std = (0.5,))])\n",
    "\n",
    "train_dataset = TrainSet(transform = composed)\n",
    "test_dataset = TestSet(transform = composed)\n",
    "\n",
    "#Make dataloader\n",
    "#Note: DataLoader antomatically transform data from numpy to tensor\n",
    "#But we still do ToTensor transform to Normalize(normalize require tensor dtype)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = 10, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show some examples to examinate dataloader\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "print(example_data.shape)\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0] , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (Conv): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU): ReLU()\n",
      "  (MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Linear): Linear(in_features=1960, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Build a Convolutional Neural Network\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.Conv = nn.Conv2d(in_channels =1, out_channels = 10, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.MaxPool = nn.MaxPool2d(2)\n",
    "        self.Linear = nn.Linear(in_features = 1960 , out_features= 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.Conv(x) #input(batch_size ,1, 28, 28), output(batch_size, 10, 28, 28)\n",
    "        output = self.ReLU(output)\n",
    "        output = self.MaxPool(output) #input(batch_size, 10, 28, 28), output(batch_size, 10, 14, 14)\n",
    "        #flatten input(batch_size, 10, 14, 14), output(batch_size, 1960)\n",
    "        output = output.view(-1, 1960)\n",
    "        #Linear input(bath_size, 1960) output(batch_size, 10)\n",
    "        output = self.Linear(output)\n",
    "        #we don't have to do softmax here, because we are use CrossEntropy, which softmax is included\n",
    "        return output\n",
    "\n",
    "model = Model().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "epoch: 1/2, step: 100/600, loss: 0.400\n",
      "epoch: 1/2, step: 200/600, loss: 0.245\n",
      "epoch: 1/2, step: 300/600, loss: 0.190\n",
      "epoch: 1/2, step: 400/600, loss: 0.218\n",
      "epoch: 1/2, step: 500/600, loss: 0.090\n",
      "epoch: 1/2, step: 600/600, loss: 0.163\n",
      "epoch: 2/2, step: 100/600, loss: 0.131\n",
      "epoch: 2/2, step: 200/600, loss: 0.100\n",
      "epoch: 2/2, step: 300/600, loss: 0.071\n",
      "epoch: 2/2, step: 400/600, loss: 0.119\n",
      "epoch: 2/2, step: 500/600, loss: 0.074\n",
      "epoch: 2/2, step: 600/600, loss: 0.095\n",
      "Training is completed\n"
     ]
    }
   ],
   "source": [
    "#Make Training Loop\n",
    "\n",
    "steps = len(train_loader)\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        #Note: Labels are now dtype torch.uint8, should be change to torch.long for CrossEntropyLoss\n",
    "        labels = labels.type(torch.long)\n",
    "        labels = labels.to(device)\n",
    "        #forward pass\n",
    "        pred_labels = model(images)\n",
    "        loss = criterion(pred_labels, labels)\n",
    "\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #update gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print information in a epoch\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch: {epoch+1}/{n_epoch}, step: {(i+1)}/{steps}, loss: {loss.item():.3f}')\n",
    "\n",
    "            \n",
    "print('Training is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.972\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "\n",
    "#Note: In test case, we do not want to calculate the gradients\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    #you can also use for i, (images, labels) in enumerate(test_loader):\n",
    "    #but now we don't care batch imformation, simple use this\n",
    "    for images, labels in test_loader:\n",
    "        #flatten\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        #the output is a probability distribution. We want to tranform them into integer(predicted state)\n",
    "        #torch.max(tensor, dimention) will return [max tensor value, index] in a dimention of a tensor\n",
    "        #here we only want the index, not the linear output(float), actually it is the predicted number\n",
    "        #Note: _ here is not probability because we didn't apply softmax\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        n_samples = n_samples + labels.shape[0]\n",
    "        #Note (predicted == labels) is still a tensor with one element. We need to use item() to get a value\n",
    "        #then we can compute divition\n",
    "        n_correct = n_correct + (predicted == labels).sum().item()\n",
    "\n",
    "acc = n_correct / n_samples\n",
    "print(f'model accuracy: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels:\n",
      " [7 2 1 0 4 1 4 9 6 9]\n",
      "actual labels:\n",
      " [7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "#See some predictions of the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    examples = iter(test_loader)\n",
    "    data, actual_labels = examples.next()\n",
    "    data = data.to(device)\n",
    "    predicted_labels = model(data)\n",
    "    _, predicted_labels = torch.max(predicted_labels, 1)\n",
    "\n",
    "print('predicted labels:\\n', predicted_labels.cpu().numpy())\n",
    "print('actual labels:\\n', actual_labels.numpy().squeeze())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f34a5bbbef19218a9b3b6792145ecf26538ebcfc8a2962317f017efbbe40c8a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('torchsegmentation': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
